{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "```kewords: tensor, 텐서 연산, 미분, Gradient Descent, ...```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 신경망과의 첫 만남"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "MNIST\r\n",
    "\r\n",
    "- 흑백 손글씨 숫자 이미지\r\n",
    "- 1980s, 미국 국립표준기술연구소 (National Institute of Standards and Technology, NIST)\r\n",
    "- train: 6만 / test: 1만\r\n",
    "- 28, 28, 1\r\n",
    "- 10개의 범주 (0 ~ 9)\r\n",
    "- 딥러닝계의 \"hello world\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(train_images.shape, len(train_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) 60000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(test_images.shape, len(test_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 28, 28) 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 전처리"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\r\n",
    "train_images = train_images.astype(\"float32\") / 255\r\n",
    "\r\n",
    "test_images = test_images.reshape((10000, 28 * 28))\r\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_labels = to_categorical(train_labels)\r\n",
    "test_labels = to_categorical(test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "network = Sequential()\r\n",
    "network.add(Dense(512, input_shape=(28 * 28,), activation=\"relu\"))\r\n",
    "network.add(Dense(10, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "network.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "신경망의 핵십 구성 요소 = 일종의 데이터 처리 필터, 층 (layer)<br />\r\n",
    "= 주어진 문제에 더 의미 있는 표현(representation)을 입력된 데이터로부터 추출.\r\n",
    "\r\n",
    "대부분의 딥러닝은 간단한 층을 연결하여 구성되며, 점진적으로 데이터를 정제하는 형태를 띤다.<br />\r\n",
    "따라서 데이터 정제 필터(층)가 연속되어 있는 데이터 프로세싱을 위한 여과기 같음."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 완전 연결(fully connected)된 신경망 층인 Dense\r\n",
    "- Softmax, exponential과 구성비를 이용한 class에 대한 확률값을 반환"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "compile을 위해 필요한 3가지\r\n",
    "- 손실 함수 loss function: 옳은 방햐응로 학습될 수 있도록 도움.\r\n",
    "- optimizer: 가중치를 update하는 algorithm\r\n",
    "- 훈련 과정을 monitoring할 지표"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "network.fit(train_images, train_labels, batch_size=128, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000018F9C4C9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000018F9C4C9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2566 - accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1029 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0492 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0374 - accuracy: 0.9888\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f9c4ed708>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\r\n",
    "print(\"test accuracy:\", test_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000018F9C6E13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000018F9C6E13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9790\n",
      "test accuracy: 0.9789999723434448\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "과대적합 (Overfitting): 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 신경망을 위한 데이터 표현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tensor\r\n",
    "\r\n",
    "- 데이터를 위한 container, 임의의 차원 개수를 가지는 행렬의 일반화된 형태\r\n",
    "- 차원 = 축, 랭크"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Scalar (0D tensor)\r\n",
    "\r\n",
    "- 스칼라 (tensor), 0차원 텐서, 0D 텐서\r\n",
    "- 숫자 하나만 담고 있는 tensor\r\n",
    "- in numpy, float32, float64 type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "x = np.array(12)\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Vector (1D tensor)\r\n",
    "\r\n",
    "- 벡터, 1D 텐서"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Matrix (2D tensor)\r\n",
    "\r\n",
    "- 행렬, 2D 텐서\r\n",
    "- 2개의 축 (행-row과 열-column)\r\n",
    "- 숫자가 채워진 사각 격자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "x = np.array([[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 5, 78,  2, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. 3D tensor ~\r\n",
    "\r\n",
    "- 3D 텐서는 숫자가 채워진 직육면체 형태로 해석할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "x = np.array(\r\n",
    "    [[[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]],\r\n",
    "     [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]],\r\n",
    "     [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]]\r\n",
    ")\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 핵심\r\n",
    "\r\n",
    "- 축, rank    : np.array(...).ndim\r\n",
    "- 크기, shape : tensor의 축에 따라 얼마나 많은 차원이 있는지, np.array(...).shape\r\n",
    "- 데이터 타입  : np.array(...).dtype\r\n",
    "  - numpy와 여러 library들이 메모리 사전 할당 문제로 가변 길이의 문자열을 지원하지 않는다.\r\n",
    "  - C언어도 아닌데 동적으로 짜면 느려진단 소리로 보인다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(train_images.ndim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(train_images.dtype)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "8bit 정수형"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "digit = train_images[4]\r\n",
    "plt.imshow(digit)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### in numpy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "slicing: 배열에 있는 특정 원소를 선택하는 것"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_slice1 = train_images[10:100]\r\n",
    "my_slice2 = train_images[10:100, :, :]\r\n",
    "my_slice3 = train_images[10:100, 0:28, 0:28]\r\n",
    "print(my_slice1.shape, my_slice2.shape, my_slice3.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_slice4 = train_images[4, 14:, 14:]\r\n",
    "plt.imshow(my_slice4)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_slice5 = train_images[4, 7:-7, 7:-7]\r\n",
    "plt.imshow(my_slice5)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 배치 데이터\r\n",
    "\r\n",
    "```batch = train_images[size * n : size * (n + 1)```\r\n",
    "\r\n",
    "- 한번에 처리하는 데이터의 양\r\n",
    "- 딥러닝에서 첫번째 축은 샘플 축이지만, 배치 데이터를 이용할 땐 배치 축(차원)이라 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 실제\r\n",
    "\r\n",
    "| name | tensor | axis | description |\r\n",
    "|:----:|:------:|------|-------------|\r\n",
    "| vector | 2d tensor | (samples, features) | 가장 기본적인 dataset, cell 표현<br />- 나이에 따른 소득세 데이터셋 |\r\n",
    "| 시계열 or Sequence(주기성) 데이터 | 3d tensor | (samples, timesteps, features) | 시간이나 연속된 순서가 중요할 때 쓰임<br />- 주식 가격 데이터셋, 트윗 데이터셋 |\r\n",
    "| image | 4d tensor | (samples, height, width, channels)<br />(samples, channels, height, width) | 픽셀을 표현하는 색 차원의 추가<br />- tensorflow: channel-last<br />- Theano: channel-first<br />- Keras는 둘 다 가능 |\r\n",
    "| video | 5d tensor | (sampels, frames, height, width, channels)<br />(samples, frames, channels, height, width) | 프레임의 연속이고, 컬러니까 |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 신경망의 톱니바퀴: 텐서 연산"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "모든 신경망 연산은 작은 텐서의 연산으로 나타낼 수 있다. 마치 파이나 곱셈을 덧셈으로 표현할 수 있듯이 말이다.\r\n",
    "\r\n",
    "- ```keras.layers.Dense(512, activation=\"relu\")```\r\n",
    "- output = relu(dot(W, input) + b)\r\n",
    "   - ```dot(W, input)``` | ```Z + b``` | ```relu(Z')```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 원소별 계산\r\n",
    "\r\n",
    "- element-wise operation\r\n",
    "- numpy 연산은 (System's) BLAS에 위임해 병렬 연산을 처리함.\r\n",
    "- BLAS: Basic Linear Algebra Subprogram (Fortan or C)\r\n",
    "- 같은 위치에 있는 얘들끼리 덧셈 및 곱셈을 하는 것."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_add(x, y):\r\n",
    "    assert len(x.shape) == 2\r\n",
    "    assert x.shape == y.shape\r\n",
    "\r\n",
    "    x = x.copy()\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] += y[i, j]\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_relu(x):\r\n",
    "    assert len(x.shape) == 2\r\n",
    "\r\n",
    "    x = x.copy()\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        x[i, j] = max(x[i, j], 0)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### broadcasting\r\n",
    "\r\n",
    "- 큰 tensor의 input에 맞도록 작은 tensor에 (broadcasting 축이라고 부르는) 축이 추가됨.\r\n",
    "- 작은 tensor가 새 축을 따라서 큰 tensor의 크기에 맞도록 반복됨."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<pre>\r\n",
    "assert x.shape == (32, 10)\r\n",
    "assert y.shape == (10,)\r\n",
    "\r\n",
    "y.reshape((0, -1))\r\n",
    "-> y.shape == (1, 10)\r\n",
    "y[i, :] = y for i in range(x.shape[0])\r\n",
    "\r\n",
    "return x + y\r\n",
    "</pre>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_add_matrix_and_vector(x, y):\r\n",
    "    assert len(x.shape) == 2\r\n",
    "    assert len(y.shape) == 1\r\n",
    "    assert x.shape[1] == y.shape[0]\r\n",
    "\r\n",
    "    x = x.copy()\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            x[i, j] += y[i]\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서 곱셈\r\n",
    "\r\n",
    "- tensor product\r\n",
    "- 원소별 연산과 반대로 입력 텐서의 원소들을 결합시킴.\r\n",
    "- (a, b, c, d) * (d, ) = (a, b, c)\r\n",
    "- (a, b, c, d) * (d, e) = (a, b, c, e)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_vecetor_dot(x, y):\r\n",
    "    assert len(x.shape) == 1\r\n",
    "    assert len(y.shape) == 1\r\n",
    "    assert x.shape[0] == y.shape[0]\r\n",
    "\r\n",
    "    z = 0.\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        z += x[i] * y[i]\r\n",
    "    return z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_matrix_vector_dot(x, y):\r\n",
    "    assert len(x.shape) == 2\r\n",
    "    assert len(y.shape) == 1\r\n",
    "    assert x.shape[1] == y.shape[0]\r\n",
    "\r\n",
    "    z = np.zeros(x.shape[0])\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(x.shape[1]):\r\n",
    "            z[i] += x[i, j] * y[j]\r\n",
    "    return z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_matrix_vector_dot(x, y):\r\n",
    "    z = np.zeros(x.shape[0])\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        z[i] = naive_vector_add(x[i, :], y)\r\n",
    "    return z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def naive_matrix_dot(x, y):\r\n",
    "    assert len(x.shape) == 2\r\n",
    "    assert len(y.shape) == 2\r\n",
    "    assert x.shape[1] == y.shape[0]\r\n",
    "\r\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\r\n",
    "    for i in range(x.shape[0]):\r\n",
    "        for j in range(y.shape[1]):\r\n",
    "            row_x = x[i, :]\r\n",
    "            column_y = y[:, j]\r\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\r\n",
    "    return z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서 크기 변환\r\n",
    "\r\n",
    "- 연산 전 전처리 용도랄까.\r\n",
    "- 대체로 **전치(Transposition)**를 가장 많이 이용"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텐서 연산의 기하학적 해석\r\n",
    "\r\n",
    "- tensor는 곧 vector로 변환될 수 있으므로, 모든 tensor 연산은 n-차원에 대한 좌표 포인트로 이해될 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 딥러닝의 기하학적 해석\r\n",
    "\r\n",
    "- 삼단논법에 의거하여, 딥러닝은 텐서 연산의 확장이고 / 텐서 연산은 그 깊이(복잡함)가 얼마든 기학학적 변환으로 해석될 수 있다.\r\n",
    "- 따라서, 딥러닝은 복잡한 텐서 연산의 집합체이므로, 기학학적 변환으로 해석될 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 신경망의 엔진: 그래디언트 기반 최적화"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}