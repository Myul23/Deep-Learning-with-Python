{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "```kewords: tensor, 텐서 연산, 미분, Gradient Descent, ...```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 굳이 할 필요 없지만, 난 하고 싶으니까\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# %matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 신경망과의 첫 만남"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "MNIST\r\n",
    "\r\n",
    "- 흑백 손글씨 숫자 이미지\r\n",
    "- 1980s, 미국 국립표준기술연구소 (National Institute of Standards and Technology, NIST)\r\n",
    "- train: 6만 / test: 1만\r\n",
    "- 28, 28, 1\r\n",
    "- 10개의 범주 (0 ~ 9)\r\n",
    "- 딥러닝계의 \"hello world\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(train_images.shape, len(train_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 28, 28) 60000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(test_images.shape, len(test_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 28, 28) 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 데이터 전처리"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\r\n",
    "train_images = train_images.astype(\"float32\") / 255\r\n",
    "\r\n",
    "test_images = test_images.reshape((10000, 28 * 28))\r\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_labels = to_categorical(train_labels)\r\n",
    "test_labels = to_categorical(test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "network = Sequential()\r\n",
    "network.add(Dense(512, input_shape=(28 * 28,), activation=\"relu\"))\r\n",
    "network.add(Dense(10, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "network.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "신경망의 핵십 구성 요소 = 일종의 데이터 처리 필터, 층 (layer)<br />\r\n",
    "= 주어진 문제에 더 의미 있는 표현(representation)을 입력된 데이터로부터 추출.\r\n",
    "\r\n",
    "대부분의 딥러닝은 간단한 층을 연결하여 구성되며, 점진적으로 데이터를 정제하는 형태를 띤다.<br />\r\n",
    "따라서 데이터 정제 필터(층)가 연속되어 있는 데이터 프로세싱을 위한 여과기 같음."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 완전 연결(fully connected)된 신경망 층인 Dense\r\n",
    "- Softmax, exponential과 구성비를 이용한 class에 대한 확률값을 반환"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "compile을 위해 필요한 3가지\r\n",
    "- 손실 함수 loss function: 옳은 방햐응로 학습될 수 있도록 도움.\r\n",
    "- optimizer: 가중치를 update하는 algorithm\r\n",
    "- 훈련 과정을 monitoring할 지표"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "network.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "network.fit(train_images, train_labels, batch_size=128, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000018F9C4C9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000018F9C4C9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2566 - accuracy: 0.9255\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1029 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0492 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0374 - accuracy: 0.9888\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f9c4ed708>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\r\n",
    "print(\"test accuracy:\", test_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000018F9C6E13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000018F9C6E13A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9790\n",
      "test accuracy: 0.9789999723434448\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "과대적합 (Overfitting): 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 경향"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 신경망을 위한 데이터 표현"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensor: 데이터를 위한 container, 임의의 차원 개수를 가지는 행렬의 일반화된 형태\r\n",
    "- 차원 = 축, 랭크"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "1. Scalar (0D tensor): 숫자 하나만 담고 있는 tensor\r\n",
    "- 스칼라 (tensor), 0차원 텐서, 0D 텐서\r\n",
    "- in numpy, float32, float64 type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "x = np.array(12)\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Vector (1D tensor)\r\n",
    "- 벡터, 1D 텐서"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Matrix (2D tensor)\r\n",
    "- 행렬, 2D 텐서\r\n",
    "- 2개의 축 (행-row과 열-column)\r\n",
    "- 숫자가 채워진 사각 격자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "x = np.array([[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]])\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 5, 78,  2, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. 3D tensor ~\r\n",
    "- 3D 텐서는 숫자가 채워진 직육면체 형태로 해석할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "x = np.array(\r\n",
    "    [[[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]],\r\n",
    "     [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]],\r\n",
    "     [[5, 78, 2, 34, 0], [6, 79, 3, 35, 1], [7, 80, 4, 36, 2]]]\r\n",
    ")\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]],\n",
       "\n",
       "       [[ 5, 78,  2, 34,  0],\n",
       "        [ 6, 79,  3, 35,  1],\n",
       "        [ 7, 80,  4, 36,  2]]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "x.ndim"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "핵심\r\n",
    "\r\n",
    "- 축, rank    : np.array(...).ndim\r\n",
    "- 크기, shape : tensor의 축에 따라 얼마나 많은 차원이 있는지, np.array(...).shape\r\n",
    "- 데이터 타입  : np.array(...).dtype\r\n",
    "  - numpy와 여러 library들이 메모리 사전 할당 문제로 가변 길이의 문자열을 지원하지 않는다.\r\n",
    "  - C언어도 아닌데 동적으로 짜면 느려진단 소리로 보인다."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}